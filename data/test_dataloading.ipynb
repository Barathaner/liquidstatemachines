{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:48:04.463760Z",
     "start_time": "2025-06-27T22:47:04.405225Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://zenkelab.org/datasets/shd_train.h5.zip to ./data/SHD/shd_train.h5.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79fb24d992b74e8581b5dc63d5796119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130863613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/SHD/shd_train.h5.zip to ./data/SHD\n"
     ]
    }
   ],
   "source": [
    "import dataloader\n",
    "trainloader= dataloader.load_filtered_shd_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cb3dee141c97d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:48:05.188503Z",
     "start_time": "2025-06-27T22:48:04.519056Z"
    }
   },
   "outputs": [],
   "source": [
    "events, target = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b680494296373a8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:48:05.294021Z",
     "start_time": "2025-06-27T22:48:05.291870Z"
    }
   },
   "outputs": [],
   "source": [
    "events[4].shape\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2040e1aea37738a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:48:05.349435Z",
     "start_time": "2025-06-27T22:48:05.344763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([250, 1, 700])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23251ca6a414d08a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:48:07.702071Z",
     "start_time": "2025-06-27T22:48:05.448179Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24689d17ad574b6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:57:03.589816Z",
     "start_time": "2025-06-27T22:57:03.587371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "num_inputs = 700\n",
    "num_hidden = 2000\n",
    "num_outputs = 10\n",
    "\n",
    "# Temporal Dynamics\n",
    "num_steps = 1000\n",
    "beta = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21d4192aee6b18e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:57:04.456017Z",
     "start_time": "2025-06-27T22:57:04.442718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):  # x: [batch, time, input]\n",
    "        batch_size, time_steps, _ = x.shape\n",
    "\n",
    "        # Initialize membrane potentials as zeros with the correct shape\n",
    "        mem1 = torch.zeros(batch_size, self.fc1.out_features, device=x.device)\n",
    "        mem2 = torch.zeros(batch_size, self.fc2.out_features, device=x.device)\n",
    "\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(time_steps):\n",
    "            xt = x[:, step, :]  # [batch, 700]\n",
    "            cur1 = self.fc1(xt)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "505ac73d16ab2584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:57:06.002925Z",
     "start_time": "2025-06-27T22:57:05.998959Z"
    }
   },
   "outputs": [],
   "source": [
    "# pass data into the network, sum the spikes over time\n",
    "# and compare the neuron with the highest number of spikes\n",
    "# with the target\n",
    "\n",
    "def print_batch_accuracy(data, targets, train=False):\n",
    "    output, _ = net(data)\n",
    "    _, idx = output.sum(dim=0).max(1)\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    if train:\n",
    "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "\n",
    "def train_printer(\n",
    "    data, targets, epoch,\n",
    "    counter, iter_counter,\n",
    "        loss_hist, test_loss_hist, test_data, test_targets):\n",
    "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
    "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
    "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
    "    print_batch_accuracy(data, targets, train=True)\n",
    "    print_batch_accuracy(test_data, test_targets, train=False)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7df4304de9a2444f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:57:06.206984Z",
     "start_time": "2025-06-27T22:57:06.203784Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9cf629221435f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:57:06.416976Z",
     "start_time": "2025-06-27T22:57:06.414054Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5448020bd783705e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:57:10.986442Z",
     "start_time": "2025-06-27T22:57:06.585789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250, 32, 10])\n"
     ]
    }
   ],
   "source": [
    "data, targets = next(iter(trainloader))\n",
    "data = data.to(device).squeeze(2).squeeze(2)  # [128, 1000, 700]\n",
    "targets = targets.to(device)\n",
    "spk_rec, mem_rec = net(data)\n",
    "print(mem_rec.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfb2f32eb80bedc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:57:10.999055Z",
     "start_time": "2025-06-27T22:57:10.990926Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19bc8abdec332102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:57:11.520816Z",
     "start_time": "2025-06-27T22:57:11.138561Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 250 is out of bounds for dimension 0 with size 250",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# sum loss at every step\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m   loss_val += loss(\u001b[43mmem_rec\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m]\u001b[49m, targets)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_val.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: index 250 is out of bounds for dimension 0 with size 250"
     ]
    }
   ],
   "source": [
    "# initialize the total loss value\n",
    "dtype = torch.float\n",
    "\n",
    "loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "\n",
    "# sum loss at every step\n",
    "for step in range(num_steps):\n",
    "  loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "print(f\"Training loss: {loss_val.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e57839114ee3aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:57:14.905771Z",
     "start_time": "2025-06-27T22:57:11.588120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for a single minibatch: 18.75%\n"
     ]
    }
   ],
   "source": [
    "print_batch_accuracy(data, targets, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8189ab9911d89dc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:57:17.519621Z",
     "start_time": "2025-06-27T22:57:14.967461Z"
    }
   },
   "outputs": [],
   "source": [
    "# clear previously stored gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# calculate the gradients\n",
    "loss_val.backward()\n",
    "\n",
    "# weight update\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be1fd562aa6f7f99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:57:23.445142Z",
     "start_time": "2025-06-27T22:57:17.570605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2231.914\n",
      "Train set accuracy for a single minibatch: 25.00%\n"
     ]
    }
   ],
   "source": [
    "# calculate new network outputs using the same data\n",
    "spk_rec, mem_rec = net(data)\n",
    "\n",
    "# initialize the total loss value\n",
    "loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "\n",
    "# sum loss at every step\n",
    "for step in range(num_steps):\n",
    "  loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "print(f\"Training loss: {loss_val.item():.3f}\")\n",
    "print_batch_accuracy(data, targets, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a633baf35328e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T22:59:44.224877Z",
     "start_time": "2025-06-27T22:57:38.602588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for a single minibatch: 21.88%\n",
      "Train set accuracy for a single minibatch: 12.50%\n",
      "Train set accuracy for a single minibatch: 12.50%\n",
      "Train set accuracy for a single minibatch: 9.38%\n",
      "Train set accuracy for a single minibatch: 9.38%\n",
      "Train set accuracy for a single minibatch: 21.88%\n",
      "Train set accuracy for a single minibatch: 15.62%\n",
      "Train set accuracy for a single minibatch: 12.50%\n",
      "Train set accuracy for a single minibatch: 28.12%\n",
      "Train set accuracy for a single minibatch: 18.75%\n",
      "Train set accuracy for a single minibatch: 9.38%\n",
      "Train set accuracy for a single minibatch: 25.00%\n",
      "Train set accuracy for a single minibatch: 9.38%\n",
      "Train set accuracy for a single minibatch: 21.88%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m train_batch = \u001b[38;5;28miter\u001b[39m(trainloader)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Minibatch training loop\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liquidstatemachines/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liquidstatemachines/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liquidstatemachines/venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/liquidstatemachines/venv/lib/python3.12/site-packages/tonic/collation.py:52\u001b[39m, in \u001b[36mPadTensors.__call__\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m     49\u001b[39m     samples_output.append(sample)\n\u001b[32m     50\u001b[39m     targets_output.append(target)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m samples_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(targets_output[\u001b[32m0\u001b[39m].shape) > \u001b[32m1\u001b[39m:\n\u001b[32m     54\u001b[39m     targets_output = torch.stack(targets_output, \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;28;01melse\u001b[39;00m -\u001b[32m1\u001b[39m) \n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0\n",
    "    train_batch = iter(trainloader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.squeeze(2).squeeze(2)\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        spk_rec, mem_rec = net(data)\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        for step in range(num_steps):\n",
    "            loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        print_batch_accuracy(data, targets, train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbe1f269f094fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd42d9d858ec914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
